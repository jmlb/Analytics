{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYTHON WRAPPER FOR NSF AWARD SEARCH API\n",
    "\n",
    "https://www.research.gov/common/webapi/awardapisearch-v1.htm\n",
    "\n",
    "As per NSF notification, there could be downtime, service disruption which are typically on weekends starting at 10PM Friday through 12PM Sunday. so, if you get an error like:\n",
    "```python\n",
    "HTTPError: HTTP Error 503: Service Temporarily Unavailable\n",
    "```\n",
    "\n",
    "it is likely because the server is going thru some maintenance.\n",
    "\n",
    "Record Offset\tNo\toffset\tEnter the record offset (always starts with 1). This is used in conjunction with results per page to fetch large data sets in chunks. For example, if a search produces 82 results and the result per page is set to 25, this will generate 4 set of pages. 3 pages will have 25 results and the last page will have 7 results. Record offset value will be\n",
    "Page 1: offset=1\n",
    "Page 2: offset=26\n",
    "Page 3: offset=51\n",
    "Page 4: offset=76\n",
    "\n",
    "\n",
    "check the website for more info\n",
    "\n",
    "save on a database SQLite for future analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "import json\n",
    "import sqlite3\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REQUEST NSF API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of existing award: \n",
      " {'response': {'award': [{'piLastName': 'Boyd', 'awardeeCity': 'Newark', 'title': 'Regulatory Pathways of the Osmotic Stress Response in Bacteria', 'id': '1656688', 'awardeeName': 'University of Delaware', 'date': '03/12/2017', 'awardeeStateCode': 'DE', 'fundsObligatedAmt': '237824', 'publicAccessMandate': '1', 'agency': 'NSF', 'piFirstName': 'Fidelma'}]}} \n",
      " \n",
      "\n",
      "Example of Non-existing award: \n",
      " {'response': {'award': []}} \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'http://api.nsf.gov/services/v1/awards.json?'\n",
    "params = urllib.parse.urlencode({'id': 1656688})\n",
    "response = urllib.request.urlopen('{}{}'.format(url, params) )\n",
    "data_r = json.loads(response.read().decode(response.info().get_param('charset') or 'utf-8'))\n",
    "print('Example of existing award: \\n {} \\n \\n'.format(data_r))\n",
    "\n",
    "params = urllib.parse.urlencode({'id': 1})\n",
    "response = urllib.request.urlopen('{}{}'.format(url, params) )\n",
    "data_r = json.loads(response.read().decode(response.info().get_param('charset') or 'utf-8'))\n",
    "print('Example of Non-existing award: \\n {} \\n \\n'.format(data_r))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{'response': {'serviceNotification': [{'notificationType': 'ERROR', 'notificationCode': 'AwardAPI-002', 'notificationMessage': 'Invalid parameter(s) sent in the request. Invalid Parameter(s) {pageStart}'}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Save data in SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page number: 1778\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 503: Service Temporarily Unavailable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-b1cc4286b23c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Page number: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'dateStart'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'offset'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mScraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-145-b1cc4286b23c>\u001b[0m in \u001b[0;36mfetch_info\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     52\u001b[0m         '''\n\u001b[1;32m     53\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mresponse_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'charset'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mresponse_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'response'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 582\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 503: Service Temporarily Unavailable"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from urllib.parse import quote\n",
    "import re\n",
    " # delays for 5 seconds\n",
    "\n",
    "\n",
    "    \n",
    "class AwardScraper():\n",
    "    \n",
    "    def __init__(self, url, folder, dbname, table_name, overwrite_db):\n",
    "        self.url = url\n",
    "        self.table_name = table_name\n",
    "        self.folder = folder\n",
    "        self.dbname = dbname\n",
    "        self.overwrite_db = overwrite_db\n",
    "        self.failed_id = []\n",
    "        self.n_fail = 0\n",
    "        self.n_awards_in_page = 0\n",
    "    \n",
    "    \n",
    "    def clean_str(self, s):\n",
    "        clean = re.sub('[^/A-Za-z0-9-%]+', ' ', s)\n",
    "        return clean\n",
    "        \n",
    "    def connect2_db(self):\n",
    "        sql_files = glob.glob(self.folder+'*.db')\n",
    "        if (self.dbname in sql_files) or (overwrite_db == False):\n",
    "            \n",
    "            self.conn = sqlite3.connect(self.folder+dbname)\n",
    "            \n",
    "            self.c = self.conn.cursor()\n",
    "        else:\n",
    "            #open connection to local file\n",
    "            self.conn = sqlite3.connect(self.folder+dbname)\n",
    "            self.c = self.conn.cursor()\n",
    "            # Create table\n",
    "            try:\n",
    "                self.c.execute(\"CREATE TABLE research_awards (id, agency, awardeeCity, awardeeName, awardeeStateCode, fundsObligatedAmount, piFirstname, piLastName, publicAccessMandate, date, title, topic))\".format(table_name))\n",
    "                print('Created Table: {} in database {}'.format(table_name, self.folder+dbname) )\n",
    "                # Save (commit) the changes\n",
    "                self.conn.commit()\n",
    "            except:\n",
    "                print('Unable to create table')\n",
    "\n",
    "            \n",
    "    \n",
    "    def fetch_info(self, request):\n",
    "        '''\n",
    "        request is a dict {'dateStart': value}\n",
    "        \n",
    "        '''\n",
    "        params = urllib.parse.urlencode(request)\n",
    "        response = urllib.request.urlopen('{}{}'.format(self.url, params), timeout=15)\n",
    "        response_json = json.loads(response.read().decode(response.info().get_param('charset') or 'utf-8'))\n",
    "        response_json = response_json['response']\n",
    "        if 'award' in response_json:\n",
    "            awards = response_json['award']\n",
    "            print('Number of awards: {}'.format(len(awards)) )\n",
    "            return awards\n",
    "        else:\n",
    "            print(response_json['serviceNotification'])\n",
    "            return [] \n",
    "    \n",
    "    \n",
    "    def clean_award_data(self, info):\n",
    "        categories = ['piLastName', 'awardeeCity', 'title', 'id', 'awardeeName', 'date', 'awardeeStateCode',\n",
    "                      'fundsObligatedAmt', 'publicAccessMandate', 'agency', 'piFirstName']\n",
    "        for category in categories:\n",
    "            if category not in info:\n",
    "                info[category] = ''\n",
    "            info[category] = self.clean_str(info[category])\n",
    "        \n",
    "        return info\n",
    "                \n",
    "        \n",
    "    \n",
    "    def save_data2db(self, item):\n",
    "        sql_command = \"SELECT research_awards.id FROM research_awards WHERE research_awards.id = '{}';\".format(item['id'])\n",
    "        try:\n",
    "            self.c.execute(sql_command)\n",
    "            result = self.c.fetchall()\n",
    "            if len(result) != 0:\n",
    "                item_in_table = True\n",
    "            else:\n",
    "                item_in_table = False\n",
    "            err_select = False\n",
    "        except:\n",
    "            # Insert a row of data\n",
    "            print('Unable to execute SQL query: SELECT')\n",
    "            err_select = True   \n",
    "        if item_in_table == False:\n",
    "            item = self.clean_award_data(item)\n",
    "            sql_command = \"INSERT INTO research_awards VALUES ('{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}');\".format(item['id'], \n",
    "            item['agency'], \n",
    "            item['awardeeCity'], item['awardeeName'], item['awardeeStateCode'], \n",
    "            item['fundsObligatedAmt'], item['piFirstName'], item['piLastName'], \n",
    "            item['publicAccessMandate'], item['date'], item['title'], \"\")\n",
    "            try:\n",
    "                self.c.execute(sql_command)\n",
    "                self.conn.commit()\n",
    "                return True\n",
    "            except:\n",
    "                print('Unable to save data on database')\n",
    "                return False\n",
    "\n",
    "            \n",
    "    def scan_page(self, page):\n",
    "        for idx in range(len(page)):\n",
    "            flag = self.save_data2db(page[idx])\n",
    "            if flag==False:\n",
    "                self.n_fail = self.n_fail + 1\n",
    "        self.n_awards_in_page = len(page)\n",
    "\n",
    "                \n",
    "                \n",
    "sleep_time = 0.01\n",
    "url = 'http://api.nsf.gov/services/v1/awards.json?'\n",
    "date ='03/16/1980'\n",
    "flder = ''\n",
    "table_name = \"research_awards\"\n",
    "dbname = 'research_grants.db'\n",
    "overwrite_db = True\n",
    "Scraper = AwardScraper(url, '', dbname, table_name, overwrite_db)\n",
    "Scraper.connect2_db()\n",
    "\n",
    "n_awards_per_page = 25\n",
    "n_awards = n_awards_per_page\n",
    "offset = 1778\n",
    "\n",
    "while n_awards > 0:\n",
    "    print('Page number: {}'.format(offset) ) \n",
    "    request = {'dateStart': date, 'offset': offset}\n",
    "    response = Scraper.fetch_info(request)\n",
    "    if len(response) != 0:\n",
    "        Scraper.scan_page(response)\n",
    "        n_awards = Scraper.n_awards_in_page\n",
    "        offset += n_awards_per_page\n",
    "    else:\n",
    "        print('Page empty')\n",
    "        n_awards = -1   \n",
    "\n",
    "#url = 'http://api.nsf.gov/services/v1/awards.json?'\n",
    "#params = urllib.parse.urlencode({'id': 1656688})\n",
    "#response = urllib.request.urlopen('{}{}'.format(url, params) )\n",
    "#data_r = json.loads(response.read().decode(response.info().get_param('charset') or 'utf-8'))\n",
    "#print('Example of existing award: \\n {} \\n \\n'.format(data_r))\n",
    "\n",
    "\n",
    "#if flag_save == True:\n",
    "#        n_award += 1\n",
    "#    #time.sleep(sleep_time)\n",
    "#    duration = round(time.time() - start, 0)\n",
    "#    if duration%100  == 0:\n",
    "#        print('Which one: ', idx)\n",
    "    \n",
    "#print('Total Number of award saved: {}'.format(n_award))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
