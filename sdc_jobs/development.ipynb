{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from indeed import IndeedClient\n",
    "import re\n",
    "client = IndeedClient(publisher =\"9124561496937265\")\n",
    "#Attribution: https://github.com/indeedlabs/indeed-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from indeed import IndeedClient\n",
    "\n",
    "client = IndeedClient(\"9124561496937265\")\n",
    "\n",
    "params = {\n",
    "    'q' : \"self-driving+car\",\n",
    "   # 'l' : \"austin\",\n",
    "    'userip' : \"1.2.3.4\",\n",
    "    'useragent' : \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_2)\"\n",
    "}\n",
    "\n",
    "search_response = client.search(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning Performance Architect\n",
      "\n",
      "Wed, 26 Apr 2017 00:07:31 GMT\n",
      "\n",
      "NVIDIA\n",
      "\n",
      "US (OR)\n",
      "\n",
      "long: -122.8022 | lat: 45.486263\n"
     ]
    }
   ],
   "source": [
    "# Example of a single examples\n",
    "this_job = search_response['results'][0]\n",
    "#print(this_job)\n",
    "#get jobkey to get more details\n",
    "this_jobkey = this_job['jobkey']\n",
    "#print(this_jobkey)\n",
    "\n",
    "#Make a query on this jobkey\n",
    "this_jobDetails = client.jobs(jobkeys = (this_jobkey, ))\n",
    "#############################\n",
    "######  JOB DETAILS  ########\n",
    "#############################\n",
    "job_title = this_jobDetails['results'][0][\"jobtitle\"]\n",
    "job_postdate = this_jobDetails['results'][0][\"date\"]\n",
    "job_employer = this_jobDetails['results'][0][\"company\"]\n",
    "job_country = this_jobDetails['results'][0][\"country\"]\n",
    "job_state = this_jobDetails['results'][0][\"state\"]\n",
    "job_gps = {'long': this_jobDetails['results'][0][\"longitude\"], 'lat': this_jobDetails['results'][0][\"latitude\"] }\n",
    "print(job_title+\"\\n\")\n",
    "print(job_postdate+\"\\n\")\n",
    "print(job_employer+\"\\n\")\n",
    "print(job_country+\" (\"+job_state+\")\\n\")\n",
    "print(\"long: {} | lat: {}\".format(job_gps['long'], job_gps['lat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # For HTML parsing\n",
    "import urllib # Website connections\n",
    "import re # Regular expressions\n",
    "from time import sleep # To prevent overwhelming the server between connections\n",
    "from collections import Counter # Keep track of our term counts\n",
    "from nltk.corpus import stopwords # Filter out stopwords, such as 'the', 'or', 'and'\n",
    "import pandas as pd # For converting results to a dataframe and bar chart plots\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#website parsing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found\n",
      "bog\n",
      "['We', 'are', 'now', 'looking', 'for', 'a', 'Deep', 'Learning', 'Performance', 'Architect', 'NVIDIA', 'is', 'seeking', 'extraordinary', 'architects', 'to', 'develop', 'processor', 'and', 'system', 'architectures', 'that', 'accelerate', 'machine', 'learning', 'data', 'analytics', 'and', 'high', 'performance', 'computing', 'applications', 'This', 'position', 'offers', 'the', 'chance', 'to', 'create', 'a', 'meaningful', 'impact', 'in', 'a', 'dynamic', 'technology', 'focused', 'company', 'What', 'you', 'will', 'be', 'doing', 'As', 'a', 'member', 'of', 'our', 'deep', 'learning', 'architecture', 'team', 'you', 'will', 'craft', 'system', 'and', 'processor', 'architectures', 'to', 'extend', 'the', 'state', 'of', 'the', 'art', 'in', 'deep', 'learning', 'efficiency', 'and', 'performance', 'Prototype', 'key', 'deep', 'learning', 'and', 'data', 'analytics', 'algorithms', 'and', 'applications', 'Analyze', 'trade', 'offs', 'in', 'performance', 'cost', 'and', 'power', 'developing', 'analytical', 'models', 'simulators', 'and', 'test', 'suites', 'Understand', 'and', 'analyze', 'the', 'interplay', 'of', 'hardware', 'and', 'software', 'architectures', 'on', 'future', 'algorithms', 'programming', 'models', 'and', 'applications', 'Collaborate', 'across', 'the', 'company', 'to', 'guide', 'the', 'direction', 'of', 'machine', 'learning', 'working', 'with', 'software', 'research', 'and', 'product', 'teams', 'What', 'we', 'need', 'to', 'see', 'You', 'have', 'a', 'MS', 'or', 'PhD', 'in', 'relevant', 'discipline', 'CS', 'EE', 'CE', 'with', '3+', 'years', 'of', 'relevant', 'work', 'or', 'research', 'experience', 'Strong', 'foundation', 'in', 'machine', 'learning', 'and', 'deep', 'learning', 'fundamentals', 'with', 'an', 'expertise', 'in', 'computer', 'architecture', 'Demonstrated', 'fluency', 'in', 'programming', 'languages', 'such', 'as', 'Python', 'C', 'C++', 'Experience', 'and', 'familiarity', 'with', 'GPU', 'computing', 'and', 'parallel', 'programming', 'models', 'Experience', 'with', 'analytical', 'performance', 'modeling', 'profiling', 'and', 'analysis', 'Intelligent', 'machines', 'powered', 'by', 'AI', 'computers', 'that', 'can', 'learn', 'reason', 'and', 'interact', 'with', 'people', 'are', 'no', 'longer', 'science', 'fiction', 'Today', 'a', 'self', 'driving', 'car', 'powered', 'by', 'artificial', 'intelligence', 'can', 'meander', 'through', 'a', 'country', 'road', 'at', 'night', 'and', 'find', 'its', 'way', 'An', 'AI', 'powered', 'robot', 'can', 'learn', 'motor', 'skills', 'through', 'trial', 'and', 'error', 'This', 'is', 'truly', 'an', 'extraordinary', 'time', 'The', 'era', 'of', 'AI', 'has', 'begun', 'Image', 'recognition', 'and', 'speech', 'recognition', 'GPU', 'deep', 'learning', 'has', 'provided', 'the', 'foundation', 'for', 'machines', 'to', 'learn', 'perceive', 'reason', 'and', 'solve', 'problems', 'The', 'GPU', 'started', 'out', 'as', 'the', 'engine', 'for', 'simulating', 'human', 'imagination', 'conjuring', 'up', 'the', 'amazing', 'virtual', 'worlds', 'of', 'video', 'games', 'and', 'Hollywood', 'films', 'Now', 'Nvidia', 's', 'GPU', 'runs', 'deep', 'learning', 'algorithms', 'simulating', 'human', 'intelligence', 'and', 'acts', 'as', 'the', 'brain', 'of', 'computers', 'robots', 'and', 'self', 'driving', 'cars', 'that', 'can', 'perceive', 'and', 'understand', 'the', 'world', 'Just', 'as', 'human', 'imagination', 'and', 'intelligence', 'are', 'linked', 'computer', 'graphics', 'and', 'artificial', 'intelligence', 'come', 'together', 'in', 'our', 'architecture', 'Two', 'modes', 'of', 'the', 'human', 'brain', 'two', 'modes', 'of', 'the', 'GPU', 'This', 'may', 'explain', 'why', 'Nvidia', 'GPUs', 'are', 'used', 'broadly', 'for', 'deep', 'learning', 'and', 'Nvidia', 'is', 'increasingly', 'known', 'as', 'the', 'AI', 'computing', 'company', 'Come', 'join', 'our', 'DL', 'Architecture', 'team', 'where', 'you', 'can', 'help', 'build', 'the', 'real', 'time', 'cost', 'effective', 'computing', 'platform', 'driving', 'our', 'success', 'in', 'this', 'exciting', 'and', 'quickly', 'growing', 'field', 'deeplearning', 'We', 'are', 'an', 'AA', 'EEO', 'Veterans', 'Disabled', 'employer']\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.indeed.com/viewjob?jk='+str(this_jobkey)\n",
    "#site = urllib.request.urlopen(url).read() # Connect to the job posting\n",
    "#soup_obj = BeautifulSoup(site, \"lxml\")\n",
    "try:\n",
    "    site = urllib.request.urlopen(url).read() # Connect to the job posting\n",
    "    soup_obj = BeautifulSoup(site, \"lxml\")\n",
    "except:\n",
    "    print('page not found')\n",
    "    #return   # Need this in case the website isn't there anymore or some other weird connection problem \n",
    "\n",
    "spans = soup_obj.find_all('span', attrs={'id':\"job_summary\"})\n",
    "for span in spans:\n",
    "    print('found')\n",
    "\n",
    "degrees = ['PhD', 'MS', 'Bachelor', 'PHD', 'BSc']\n",
    "eduFields = ['CS', 'CE', 'EE', 'Physics']\n",
    "\n",
    "domains = {'machine': ['learning'], 'Deep': ['Learning'], 'computer': ['architecture'], 'Algorithms':[], \n",
    "                'GPU': ['computing'], 'parallel': ['programming'], 'Computer': ['Vision']}\n",
    "\n",
    "progSkills = ['C++', 'C', 'C#', 'Python', 'python', 'OpenCV', 'openCV']\n",
    "\n",
    "#convert soup object to text\n",
    "text = spans[0].get_text()\n",
    "\n",
    "\n",
    "#Cleaning text\n",
    "try:\n",
    "    text = text.decode('unicode_escape').encode('ascii', 'ignore') \n",
    "except:                                 \n",
    "    print('bog')\n",
    "\n",
    "#Remove special characters\n",
    "special_chars = \"!@#$%^&*()[]{};:,./<>?\\|`~=_\"\n",
    "for special_char in special_chars:\n",
    "    text = text.replace(special_char, \" \")\n",
    "#remove newline\n",
    "text = \" \".join(text.split())\n",
    "\n",
    "text = re.sub(\"[^a-zA-Z.+3]\",\" \", text)  # Now get rid of any terms that aren't words (include 3 for d3.js)\n",
    "                                                # Also include + for C++\n",
    "text_split = text.split()\n",
    "print(text_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'progSkills': ['Python', 'C', 'C++'], 'degrees': ['MS', 'PhD'], 'eduFields': ['CS', 'EE', 'CE'], 'domains': ['machine learning', 'computer architecture', 'parallel programming']}\n"
     ]
    }
   ],
   "source": [
    "job_fields = ['degrees', 'eduFields', 'domains', 'progSkills']\n",
    "\n",
    "this_job = {}\n",
    "#Initialize\n",
    "for i in job_fields:\n",
    "    this_job[i] = []\n",
    "\n",
    "#better to scroll thru text once\n",
    "for idx, word in enumerate(text_split):\n",
    "    w_lower = word.lower()\n",
    "    if word in degrees:\n",
    "        if len(this_job['degrees'])==0:\n",
    "            this_job['degrees'] = [word]\n",
    "        else:\n",
    "            this_job['degrees'].append(word)\n",
    "\n",
    "    if word in eduFields:\n",
    "        if len(this_job['eduFields'])==0:\n",
    "            this_job['eduFields'] = [word]\n",
    "        else:\n",
    "            this_job['eduFields'].append(word)\n",
    "    \n",
    "    if w_lower in domains:\n",
    "        next_word = text_split[idx+1]\n",
    "        if next_word.lower() in domains[w_lower]:\n",
    "            # word+next_word combination \n",
    "            if len(this_job['domains'])==0:\n",
    "                this_job['domains'] = [w_lower+\" \"+next_word.lower()]\n",
    "            else:\n",
    "                domain = w_lower+\" \"+next_word.lower()\n",
    "                if domain not in this_job['domains']:\n",
    "                    this_job['domains'].append(domain)\n",
    "    \n",
    "    if word in progSkills:\n",
    "        if len(this_job['progSkills'])==0:\n",
    "            this_job['progSkills'] = [word]\n",
    "        else:\n",
    "            this_job['progSkills'].append(word) \n",
    "            \n",
    "\n",
    "print(this_job)\n",
    "\n",
    "\n",
    "#convert soup object to text\n",
    "#text_split = text.lower().split()\n",
    "#print(text_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
